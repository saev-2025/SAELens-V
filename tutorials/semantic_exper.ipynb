{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,Dataset,load_from_disk,Image\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "from sae_lens.activation_visualization import load_llava_model,load_sae,generate_with_saev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please replace these path to your own path\n",
    "MODEL_NAME = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
    "model_path = \"\"\n",
    "device = \"cuda:0\"\n",
    "sae_device = \"cuda:7\"\n",
    "sae_path = \"\"\n",
    "dataset_path = \"\"\n",
    "columns_to_read = [\"input_ids\", \"pixel_values\", \"attention_mask\", \"image_sizes\"]\n",
    "\n",
    "save_path = \"\"\n",
    "\n",
    "\n",
    "(\n",
    "        processor,\n",
    "        hook_language_model,\n",
    ") = load_llava_model(MODEL_NAME, model_path, device,n_devices=8)\n",
    "\n",
    "sae = load_sae(sae_path, sae_device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"\"\"You are provided with an image and a list of 10 possible labels. Your task is to classify the image by selecting the most appropriate label from the list below:\n",
    "\n",
    "Labels:\n",
    "0: \"bonnet, poke bonnet\"\n",
    "1: \"green mamba\"\n",
    "2: \"langur\"\n",
    "3: \"Doberman, Doberman pinscher\"\n",
    "4: \"gyromitra\"\n",
    "5: \"Saluki, gazelle hound\"\n",
    "6: \"vacuum, vacuum cleaner\"\n",
    "7: \"window screen\"\n",
    "8: \"cocktail shaker\"\n",
    "9: \"garden spider, Aranea diademata\"\n",
    "\n",
    "Carefully analyze the content of the image and identify which label best describes it. Then, output only the **corresponding number** from the list without any additional text or explanation.\n",
    "\"\"\"\n",
    "local_dataset = load_from_disk(dataset_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_dataset['label'])\n",
    "print(local_dataset['image'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "system_prompt= \" \"\n",
    "user_prompt= 'USER: \\n<image> {input}'\n",
    "assistant_prompt= '\\nASSISTANT: {output}'\n",
    "def prepare_inputs(prompt,image,processor):\n",
    "    image = image.resize((336, 336)).convert('RGBA')\n",
    "    formatted_prompt = f'{system_prompt}{user_prompt.format(input=prompt)}{assistant_prompt.format(output=\"\")}'\n",
    "    text_input = processor.tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
    "    image_input = processor.image_processor(images=image, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"input_ids\": text_input[\"input_ids\"],\n",
    "        \"attention_mask\": text_input[\"attention_mask\"],\n",
    "        \"pixel_values\": image_input[\"pixel_values\"],\n",
    "        \"image_sizes\": image_input[\"image_sizes\"],\n",
    "    }\n",
    "\n",
    "input_list= []\n",
    "image_path=\"\"\n",
    "image=Image.open(image_path)\n",
    "inputs=prepare_inputs(example_prompt,image,processor)\n",
    "\n",
    "print(inputs[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cosi_file_path = \"\" \n",
    "\n",
    "\n",
    "osi_list = []\n",
    "with open(cosi_file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        key, value = line.strip().split(\",\") \n",
    "        \n",
    "        osi_list.append((int(key), float(value)))\n",
    "\n",
    "print(osi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_list = []\n",
    "image_list = []\n",
    "with tqdm.tqdm(total=len(input_list)) as pbar:\n",
    "    for inputs,data in zip(input_list,local_dataset):\n",
    "        inputs={\n",
    "            \"input_ids\": inputs[\"input_ids\"].to(device),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].to(device),\n",
    "            \"pixel_values\": inputs[\"pixel_values\"].to(device),\n",
    "            \"image_sizes\": inputs[\"image_sizes\"].to(device),\n",
    "        }\n",
    "        total_activation_l0_norms_list,patch_features_list,feature_act_list,image_indice,output=generate_with_saev(\n",
    "                inputs, hook_language_model, processor, save_path, data[\"image\"], sae, sae_device,max_new_tokens=1,selected_feature_indices=osi_list,\n",
    "            )\n",
    "        output_list.append(output[-1])\n",
    "        image_list.append({\"image\":data[\"image\"].resize((336, 336)),\"label\":data[\"label\"],\"activation_l0\":total_activation_l0_norms_list[0]})\n",
    "        pbar.update(1)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_list[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Features, Array3D, Array2D,ClassLabel, Value\n",
    "import numpy as np\n",
    "import datasets\n",
    "raw_data = []\n",
    "for idx, entry in enumerate(image_list):\n",
    "    img_array = np.array(entry['image'])\n",
    "    label = entry['label']\n",
    "    activation = np.array(entry['activation_l0'], dtype=np.float32)\n",
    "\n",
    "    if img_array.ndim == 2:\n",
    "        if img_array.shape == (336, 336):\n",
    "            img_array = np.stack([img_array]*3, axis=-1)\n",
    "        else:\n",
    "            raise ValueError(f\"Image at index {idx} has unexpected shape {img_array.shape}\")\n",
    "    elif img_array.shape == (336, 336, 4):\n",
    "        img_array = img_array[..., :3]\n",
    "\n",
    "    if img_array.shape != (336, 336, 3):\n",
    "        raise ValueError(f\"Image at index {idx} has shape {img_array.shape}, expected (336, 336, 3)\")\n",
    "    if img_array.dtype != np.uint8:\n",
    "        img_array = img_array.astype(np.uint8)\n",
    "\n",
    "    if activation.ndim == 1:\n",
    "        if activation.size == 24*24:\n",
    "            activation = activation.reshape((24, 24))\n",
    "        else:\n",
    "            raise ValueError(f\"Activation at index {idx} has size {activation.size}, cannot reshape to (24,24)\")\n",
    "    elif activation.shape != (24, 24):\n",
    "        raise ValueError(f\"Activation at index {idx} has shape {activation.shape}, expected (24,24)\")\n",
    "\n",
    "    if activation.dtype != np.float32:\n",
    "        activation = activation.astype(np.float32)\n",
    "\n",
    "    raw_data.append({\"image\": img_array, \"label\": label, \"activation_l0\": activation})\n",
    "\n",
    "raw_data_dict = {\n",
    "    \"image\": [entry[\"image\"] for entry in raw_data],\n",
    "    \"label\": [entry[\"label\"] for entry in raw_data],\n",
    "    \"activation_cosi\": [entry['activation_l0'] for entry in raw_data] \n",
    "}\n",
    "\n",
    "\n",
    "label_names = sorted(list(set(raw_data_dict[\"label\"])))  \n",
    "\n",
    "features = Features({\n",
    "    \"image\": datasets.Image(), \n",
    "    \"label\": ClassLabel(names=label_names),             \n",
    "    \"activation_cosi\": Array2D(dtype=\"float32\", shape=(24, 24))   \n",
    "})\n",
    "\n",
    "\n",
    "raw_hf_dataset = Dataset.from_dict(raw_data_dict, features=features)\n",
    "\n",
    "\n",
    "print(raw_hf_dataset)\n",
    "\n",
    "raw_hf_dataset.save_to_disk(\"imagenet10_activated_cosi_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=1000\n",
    "acc=0\n",
    "for i,output in enumerate(output_list):\n",
    "    if output == str(local_dataset[i]['label']):\n",
    "        acc+=1\n",
    "print(acc)\n",
    "print(f\"accuracy:{acc/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_list[0]['activation'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import datasets\n",
    "from datasets import Dataset, Features, Array3D, ClassLabel\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold_percentile = 25  \n",
    "mask_image_list = []\n",
    "\n",
    "for item in image_list:\n",
    "    img = item['image']\n",
    "    activation_mask = item['activation_l0']\n",
    "    \n",
    "    if isinstance(img, Image.Image):\n",
    "        img = np.array(img)\n",
    "    \n",
    "    if img.ndim == 2:\n",
    "        img = np.stack([img] * 3, axis=-1)  \n",
    "    patch_count = 24\n",
    "    patch_size = 336 // patch_count\n",
    "    activation_mask = np.array(activation_mask).reshape(patch_count, patch_count)\n",
    "    \n",
    "    threshold = np.percentile(activation_mask, threshold_percentile)\n",
    "    \n",
    "    for i in range(patch_count):\n",
    "        for j in range(patch_count):\n",
    "            if activation_mask[i, j] <= threshold:\n",
    "                img[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size, :] = 0\n",
    "\n",
    "    mask_image_list.append({\"image\":Image.fromarray(img),\"label\":item['label']})\n",
    "    \n",
    "data = []\n",
    "for entry in mask_image_list:\n",
    "    img_array = np.array(entry['image'])  \n",
    "    label = entry['label']             \n",
    "    data.append({\"image\": img_array, \"label\": label})\n",
    "\n",
    "data_dict = {\n",
    "    \"image\": [entry[\"image\"] for entry in data],\n",
    "    \"label\": [entry[\"label\"] for entry in data]\n",
    "}\n",
    "\n",
    "features = Features({\n",
    "    \"image\": datasets.Image(),  \n",
    "    \"label\": ClassLabel(names=list(set(data_dict[\"label\"])))  \n",
    "})\n",
    "\n",
    "hf_dataset = Dataset.from_dict(data_dict, features=features)\n",
    "\n",
    "print(hf_dataset)\n",
    "hf_dataset.save_to_disk(f\"imagenet10_cosi_mask{100-threshold_percentile}_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mask_image_list[0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from datasets import load_from_disk, Dataset, Features, ClassLabel as DsImage\n",
    "import datasets\n",
    "data = load_from_disk(\"\")\n",
    "\n",
    "def sample_patches(example, keep_ratio):\n",
    "    image = example[\"image\"]\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = Image.fromarray(np.uint8(image))\n",
    "    image = image.resize((336,336)).convert('RGB') \n",
    "\n",
    "    image = np.array(image) \n",
    "    h, w, c = image.shape\n",
    "    patch_size = 14\n",
    "    num_patches_h = h // patch_size\n",
    "    num_patches_w = w // patch_size\n",
    "    total_patches = num_patches_h * num_patches_w\n",
    "\n",
    "    keep_count = int(total_patches * keep_ratio)\n",
    "    keep_indices = set(np.random.choice(total_patches, keep_count, replace=False))\n",
    "\n",
    "    new_image = image.copy()\n",
    "    patch_index = 0\n",
    "    for i in range(num_patches_h):\n",
    "        for j in range(num_patches_w):\n",
    "            if patch_index not in keep_indices:\n",
    "                new_image[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size, :] = 0\n",
    "            patch_index += 1\n",
    "    \n",
    "    new_image = Image.fromarray(new_image.astype(np.uint8))\n",
    "    return new_image\n",
    "\n",
    "keep_ratio = 0.75  \n",
    "new_images = []\n",
    "new_labels = [] \n",
    "\n",
    "for i in range(len(data)):\n",
    "    example = data[i]\n",
    "    transformed_image = sample_patches(example, keep_ratio=keep_ratio)\n",
    "    transformed_array = np.array(transformed_image)\n",
    "    new_images.append(transformed_array)\n",
    "    new_labels.append(example[\"label\"])\n",
    "\n",
    "features = Features({\n",
    "    \"image\": datasets.Image(),\n",
    "    \"label\": data.features[\"label\"]  \n",
    "})\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"image\": new_images, \"label\": new_labels}, features=features)\n",
    "\n",
    "new_dataset.save_to_disk(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#119 206 633 841\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from datasets import load_from_disk, Dataset, Features, ClassLabel as DsImage\n",
    "import datasets\n",
    "\n",
    "data=load_from_disk(\"\")\n",
    "display(data[841][\"image\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
